{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 60\n",
    "\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import requests\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import *\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "months = dict(zip(['августа',\n",
    " 'апреля',  'декабря',  'июля',\n",
    " 'июня',  'марта',  'мая',\n",
    " 'ноября',  'октября',  'сентября',\n",
    " 'февраля',  'января'], [8, 4, 12, 7, 6, 3, 5, 11, 10, 9, 2, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s=Service(ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !\"{sys.executable}\" -m pip install --upgrade webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read already gathered data\n",
    "\n",
    "# df_first_articles = pd.DataFrame()\n",
    "# for i in os.listdir(os.getcwd()):\n",
    "#     if i.find(\".csv\") > -1:\n",
    "#         df_temp = pd.read_csv(i, sep=\";\")        \n",
    "#         df_first_articles = pd.concat([df_first_articles, df_temp], sort=True)\n",
    "# df_first_articles.columns=[\"num\", \"datestr\", \"type\", \"header\", \"text\", \"url\"]\n",
    "# df_first_articles = df_first_articles.sort_values(by=['num']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1: парсим новый сайт ЦБ\n",
    "### Выгрузка пресс-релизов, новостей и выступлений\n",
    "https://www.cbr.ru/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two windows: one with the main site and one for sub-windows\n",
    "\n",
    "url = \"https://www.cbr.ru/\"\n",
    "\n",
    "driver_base = webdriver.Chrome(service=s)\n",
    "driver_base.maximize_window()\n",
    "driver_base.get(url)\n",
    "parent_tab = driver_base.window_handles[0]\n",
    "\n",
    "driver_runner1 = webdriver.Chrome(service=s)\n",
    "driver_runner1.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собираем в 4 этапа: \n",
    "# Новости\n",
    "# Пресс-релизы\n",
    "# Интервью - не нужно\n",
    "# Выступления\n",
    "\n",
    "# Так как приходится кликать разделы вручную :(\n",
    "# Запустить кликер -> считать категорию -> обновить страницу -> повторить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_by_type(articles_headers, articles_links):\n",
    "    counter = 0\n",
    "    articles = []\n",
    "    exception_articles = []\n",
    "    for header, link in tqdm(zip(articles_headers, articles_links)):\n",
    "        counter += 1\n",
    "        try:\n",
    "            article_type = header.text.split(\"\\n\")[-1]\n",
    "            article_url = link.get_attribute(name='href')\n",
    "            driver_runner1.get(article_url)\n",
    "            article_date = driver_runner1.find_elements(By.TAG_NAME, value='.news-info-line_date')[0].text\n",
    "            article_text = [a.text for a in driver_runner1.find_elements(By.TAG_NAME, value='p')]\n",
    "            articles.append([counter, article_date, article_type, link.text, \"\\n\".join(article_text).strip(), article_url])\n",
    "        except Exception as e:\n",
    "            print(\"Problem!\")\n",
    "            exception_articles.append((header, link))  \n",
    "    return articles, exception_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n",
      "End reached!\n",
      "Wall time: 1.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Clicker!\n",
    "# Click all buttons \"Загрузить ещё\" to get all the news in one window\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        buttons = driver_base.find_elements(By.TAG_NAME, value='#_buttonLoadNextEvt')\n",
    "        button = [i for i in buttons if i.text == 'Загрузить еще']\n",
    "        button[0].click()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"End reached!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1020 1020\n"
     ]
    }
   ],
   "source": [
    "news_headers = driver_base.find_elements(By.TAG_NAME, value='.news_info')\n",
    "news_links = driver_base.find_elements(By.TAG_NAME, value='.news_title')\n",
    "print(len(news_headers), len(news_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1020it [13:22,  1.27it/s]\n"
     ]
    }
   ],
   "source": [
    "news_articles, news_exc = parse_by_type(news_headers, news_links)\n",
    "\n",
    "df_news_new = pd.DataFrame(news_articles)\n",
    "df_news_new = df_news_new[df_news_new[2] != \"\"].reset_index(drop=True)\n",
    "df_news_new[0] = df_news_new[0] - 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1020 1020\n"
     ]
    }
   ],
   "source": [
    "pr_headers = driver_base.find_elements(By.TAG_NAME, value='.news_info')\n",
    "pr_links = driver_base.find_elements(By.TAG_NAME, value='.news_title')\n",
    "print(len(pr_headers), len(pr_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_articles, pr_exc = parse_by_type(pr_headers, pr_links)\n",
    "\n",
    "df_pr_new = pd.DataFrame(pr_articles)\n",
    "df_pr_new = df_pr_new[df_pr_new[2] != \"\"].reset_index(drop=True)\n",
    "df_pr_new[0] = df_pr_new[0] - 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_pr_new.reset_index().iloc[720:]\n",
    "a[a['index'] != a[0] -2]\n",
    "df_pr_new.iloc[740:760]\n",
    "# header, link = pr_exc[1]\n",
    "\n",
    "# article_type = header.text.split(\"\\n\")[-1]\n",
    "# article_url = link.get_attribute(name='href')\n",
    "# driver_runner1.get(article_url)\n",
    "# # article_date = driver_runner1.find_elements(By.TAG_NAME, value='.news-info-line_date')[0].text\n",
    "# article_text = [a.text for a in driver_runner1.find_elements(By.TAG_NAME, value='p')]\n",
    "# article_date = \"11 марта 2020 года\"\n",
    "\n",
    "# df_pr_new = df_pr_new.append([[760, article_date, article_type, link.text, \"\\n\".join(article_text).strip(), article_url]])\n",
    "# df_pr_new = df_pr_new.sort_values(by=[0]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 153\n"
     ]
    }
   ],
   "source": [
    "speech_headers = driver_base.find_elements(By.TAG_NAME, value='.news_info')\n",
    "speech_links = driver_base.find_elements(By.TAG_NAME, value='.news_title')\n",
    "print(len(speech_headers), len(speech_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "153it [05:55,  2.32s/it]\n"
     ]
    }
   ],
   "source": [
    "speech_articles, speech_exc = parse_by_type(speech_headers, speech_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speech_new = pd.DataFrame(speech_articles)\n",
    "df_speech_new = df_speech_new[df_speech_new[2] != \"\"].reset_index(drop=True)\n",
    "df_speech_new[0] = df_speech_new[0] - 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame()\n",
    "for df_articles_temp, name in zip([df_news_new, df_pr_new, df_speech_new], [\"news\",\"press_rel\",\"speech\"]):\n",
    "    df_articles_temp.to_csv(f\"{name}_new.csv\", \n",
    "                            encoding=\"utf-8\", sep=\";\", index=False)\n",
    "    df_new = pd.concat([df_new, df_articles_temp])\n",
    "df_new.columns=[\"num\", \"datestr\", \"type\", \"header\", \"text\", \"url\"]\n",
    "df_new = df_new.drop(columns=['num'])\n",
    "df_new = df_new.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Здесь можно забрать готовые данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame()\n",
    "for name in [\"news\",\"press_rel\",\"speech\"]:\n",
    "    df_articles_temp = pd.read_csv(f\"{name}_new.csv\", \n",
    "                            encoding=\"utf-8\", sep=\";\")\n",
    "    df_new = pd.concat([df_new, df_articles_temp])\n",
    "df_new.columns=[\"num\", \"datestr\", \"type\", \"header\", \"text\", \"url\"]\n",
    "df_new = df_new.drop(columns=['num'])\n",
    "df_new = df_new.reset_index(drop=True)\n",
    "\n",
    "df_new['date'] = [f\"{i[0]}-{months[i[1]]}-{i[2]}\" for i in df_new.datestr.str.split().tolist()]\n",
    "df_new['date'] = pd.to_datetime(df_new['date'], format='%d-%m-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datestr</th>\n",
       "      <th>type</th>\n",
       "      <th>header</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21 февраля 2022 года</td>\n",
       "      <td>Новость</td>\n",
       "      <td>Объем средств на счетах эскроу в долевом строи...</td>\n",
       "      <td>Объем средств, размещенных участниками долевог...</td>\n",
       "      <td>https://www.cbr.ru/press/event/?id=12705</td>\n",
       "      <td>2022-02-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17 февраля 2022 года</td>\n",
       "      <td>Новость</td>\n",
       "      <td>Мониторинг отраслевых финансовых потоков: рост...</td>\n",
       "      <td>Динамика отраслевых финансовых потоков указыва...</td>\n",
       "      <td>https://www.cbr.ru/press/event/?id=12702</td>\n",
       "      <td>2022-02-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17 февраля 2022 года</td>\n",
       "      <td>Новость</td>\n",
       "      <td>В январе инфляция ускорилась в большинстве рег...</td>\n",
       "      <td>Годовая инфляция в январе находилась в диапазо...</td>\n",
       "      <td>https://www.cbr.ru/press/event/?id=12701</td>\n",
       "      <td>2022-02-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17 февраля 2022 года</td>\n",
       "      <td>Новость</td>\n",
       "      <td>Банк России разработал детскую игру о признака...</td>\n",
       "      <td>Игра «Космический детектив: тайна семи банкнот...</td>\n",
       "      <td>https://www.cbr.ru/press/event/?id=12698</td>\n",
       "      <td>2022-02-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16 февраля 2022 года</td>\n",
       "      <td>Новость</td>\n",
       "      <td>В 2021 году Банк России выявил почти 2,7 тысяч...</td>\n",
       "      <td>Среди них 871 финансовая пирамида (в 2020 году...</td>\n",
       "      <td>https://www.cbr.ru/press/event/?id=12695</td>\n",
       "      <td>2022-02-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                datestr     type  \\\n",
       "0  21 февраля 2022 года  Новость   \n",
       "1  17 февраля 2022 года  Новость   \n",
       "2  17 февраля 2022 года  Новость   \n",
       "3  17 февраля 2022 года  Новость   \n",
       "4  16 февраля 2022 года  Новость   \n",
       "\n",
       "                                              header  \\\n",
       "0  Объем средств на счетах эскроу в долевом строи...   \n",
       "1  Мониторинг отраслевых финансовых потоков: рост...   \n",
       "2  В январе инфляция ускорилась в большинстве рег...   \n",
       "3  Банк России разработал детскую игру о признака...   \n",
       "4  В 2021 году Банк России выявил почти 2,7 тысяч...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Объем средств, размещенных участниками долевог...   \n",
       "1  Динамика отраслевых финансовых потоков указыва...   \n",
       "2  Годовая инфляция в январе находилась в диапазо...   \n",
       "3  Игра «Космический детектив: тайна семи банкнот...   \n",
       "4  Среди них 871 финансовая пирамида (в 2020 году...   \n",
       "\n",
       "                                        url       date  \n",
       "0  https://www.cbr.ru/press/event/?id=12705 2022-02-21  \n",
       "1  https://www.cbr.ru/press/event/?id=12702 2022-02-17  \n",
       "2  https://www.cbr.ru/press/event/?id=12701 2022-02-17  \n",
       "3  https://www.cbr.ru/press/event/?id=12698 2022-02-17  \n",
       "4  https://www.cbr.ru/press/event/?id=12695 2022-02-16  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datestr                                  1 августа 2019 года\n",
       "type                                             Пресс-релиз\n",
       "header     А. Данилов назначен директором Департамента об...\n",
       "text       1. В целях применения абзаца второго и третьег...\n",
       "url        https://www.cbr.ru/press/pr/?file=01022021_084...\n",
       "date                                     2019-07-17 00:00:00\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new[df_new.type == \"Пресс-релиз\"].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2: парсим старый сайт ЦБ\n",
    "### Выгрузка пресс-релизов, новостей и выступлений\n",
    "http://old.cbr.ru/press/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://old.cbr.ru/press/month_archive/press_archive/\"\n",
    "\n",
    "driver_base = webdriver.Chrome(service=s)\n",
    "driver_base.maximize_window()\n",
    "driver_base.get(url)\n",
    "parent_tab = driver_base.window_handles[0]\n",
    "\n",
    "driver_runner1 = webdriver.Chrome(service=s)\n",
    "driver_runner1.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2010, 1, 1)\n",
    "end_date = datetime.date(2019, 7, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [],
   "source": [
    "DETECTED = df.url.tolist() \n",
    "\n",
    "def half_parser(cur_date, end_date, counter):\n",
    "    exc_articles = []\n",
    "    good_articles = []\n",
    "    \n",
    "    driver_base.find_elements(By.TAG_NAME, value='.hasDatepicker')[0].send_keys(\"\\b\\b\\b\\b\\b\\b\\b\\b\\b\\b\" + cur_date.strftime(\"%d.%m.%Y\"))\n",
    "    driver_base.find_elements(By.TAG_NAME, value='.hasDatepicker')[1].send_keys(\"\\b\\b\\b\\b\\b\\b\\b\\b\\b\\b\" + end_date.strftime(\"%d.%m.%Y\"))\n",
    "    driver_base.find_elements(By.TAG_NAME, value='#UniDbQuery_searchbutton')[0].click()\n",
    "\n",
    "    articles_dates = driver_base.find_elements(By.TAG_NAME, value='.source')\n",
    "    articles_links = driver_base.find_elements(By.TAG_NAME, value='a')[15:-10]\n",
    "    for article_date, link in tqdm(zip(articles_dates, articles_links)):\n",
    "        if link.get_attribute(name='href') in DETECTED:\n",
    "            continue\n",
    "        counter += 1\n",
    "        try:\n",
    "            article_type = \"Пресс-релиз\"\n",
    "            article_url = link.get_attribute(name='href')\n",
    "            driver_runner1.get(article_url)\n",
    "            article_text = [a.text for a in driver_runner1.find_elements(By.TAG_NAME, value='p')]\n",
    "            good_articles.append([counter, article_date.text, article_type, link.text, \"\\n\".join(article_text).strip(), article_url])\n",
    "        except Exception as e:\n",
    "            print(\"Problem!\")\n",
    "            exc_articles.append((article_date, link)) \n",
    "    return good_articles, exc_articles, counter\n",
    "\n",
    "\n",
    "counter = 0\n",
    "cur_date = start_date\n",
    "temp_end = cur_date + relativedelta(months=+1) - relativedelta(days=+1)\n",
    "exc_articles = []\n",
    "good_articles = []\n",
    "while temp_end < end_date:\n",
    "    print(cur_date, \" - \", temp_end)\n",
    "    \n",
    "    good_articles_temp, exc_articles_temp, counter = half_parser(cur_date, cur_date + relativedelta(days=+6), counter)\n",
    "    good_articles += good_articles_temp\n",
    "    exc_articles += exc_articles_temp\n",
    "    \n",
    "    good_articles_temp, exc_articles_temp, counter = half_parser(cur_date + relativedelta(days=+7), \n",
    "                                                                 cur_date + relativedelta(days=+13), counter)\n",
    "    good_articles += good_articles_temp\n",
    "    exc_articles += exc_articles_temp\n",
    "\n",
    "    good_articles_temp, exc_articles_temp, counter = half_parser(cur_date + relativedelta(days=+14), \n",
    "                                                                 cur_date + relativedelta(days=+20), counter)\n",
    "    good_articles += good_articles_temp\n",
    "    exc_articles += exc_articles_temp\n",
    "    \n",
    "    good_articles_temp, exc_articles_temp, counter = half_parser(cur_date + relativedelta(days=+21), \n",
    "                                                                 cur_date + relativedelta(days=+23), counter)\n",
    "    good_articles += good_articles_temp\n",
    "    exc_articles += exc_articles_temp\n",
    "    \n",
    "    good_articles_temp, exc_articles_temp, counter = half_parser(cur_date + relativedelta(days=+24), temp_end, counter)\n",
    "    good_articles += good_articles_temp\n",
    "    exc_articles += exc_articles_temp\n",
    "\n",
    "    if cur_date.month == 2:\n",
    "        pd.DataFrame(good_articles).to_csv(f\"{cur_date}_old_truely_all_arts.csv\", encoding=\"utf-8\", sep=\";\", index=False)    \n",
    "\n",
    "    cur_date = cur_date + relativedelta(months=+1)\n",
    "    temp_end = cur_date + relativedelta(months=+1) - relativedelta(days=+1)\n",
    "    temp_end = min([temp_end, end_date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(good_articles).to_csv(f\"old_all_truely_all_arts.csv\", encoding=\"utf-8\", sep=\";\", index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datestr</th>\n",
       "      <th>type</th>\n",
       "      <th>header</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.07.2014</td>\n",
       "      <td>Пресс-релиз</td>\n",
       "      <td>О продаже принадлежащих Банку России обыкновен...</td>\n",
       "      <td>В целях выполнения требования Федерального зак...</td>\n",
       "      <td>http://www.cbr.ru/press/PR/?file=01072014_1850...</td>\n",
       "      <td>2014-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.07.2014</td>\n",
       "      <td>Пресс-релиз</td>\n",
       "      <td>Об Указании Банка России от 23 апреля 2014 год...</td>\n",
       "      <td>Банк России издал Указание Банка России от 23 ...</td>\n",
       "      <td>http://www.cbr.ru/press/PR/?file=01072014_1836...</td>\n",
       "      <td>2014-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.07.2014</td>\n",
       "      <td>Пресс-релиз</td>\n",
       "      <td>О прекращении деятельности временной администр...</td>\n",
       "      <td>В связи с решением Арбитражного суда города Мо...</td>\n",
       "      <td>http://www.cbr.ru/press/PR/?file=17072014_1430...</td>\n",
       "      <td>2014-07-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.07.2014</td>\n",
       "      <td>Пресс-релиз</td>\n",
       "      <td>О решении Банка России от 16 июля 2014 года</td>\n",
       "      <td>Решение Банка России от 16 июля 2014 года:\\n\\n...</td>\n",
       "      <td>http://www.cbr.ru/press/PR/?file=17072014_1615...</td>\n",
       "      <td>2014-07-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.07.2014</td>\n",
       "      <td>Пресс-релиз</td>\n",
       "      <td>Перечень кредитных организаций, в которые назн...</td>\n",
       "      <td>Уполномоченные представители Банка России, дей...</td>\n",
       "      <td>http://www.cbr.ru/press/PR/?file=17072014_2043...</td>\n",
       "      <td>2014-07-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      datestr         type                                             header  \\\n",
       "0  01.07.2014  Пресс-релиз  О продаже принадлежащих Банку России обыкновен...   \n",
       "1  01.07.2014  Пресс-релиз  Об Указании Банка России от 23 апреля 2014 год...   \n",
       "2  17.07.2014  Пресс-релиз  О прекращении деятельности временной администр...   \n",
       "3  17.07.2014  Пресс-релиз        О решении Банка России от 16 июля 2014 года   \n",
       "4  17.07.2014  Пресс-релиз  Перечень кредитных организаций, в которые назн...   \n",
       "\n",
       "                                                text  \\\n",
       "0  В целях выполнения требования Федерального зак...   \n",
       "1  Банк России издал Указание Банка России от 23 ...   \n",
       "2  В связи с решением Арбитражного суда города Мо...   \n",
       "3  Решение Банка России от 16 июля 2014 года:\\n\\n...   \n",
       "4  Уполномоченные представители Банка России, дей...   \n",
       "\n",
       "                                                 url       date  \n",
       "0  http://www.cbr.ru/press/PR/?file=01072014_1850... 2014-07-01  \n",
       "1  http://www.cbr.ru/press/PR/?file=01072014_1836... 2014-07-01  \n",
       "2  http://www.cbr.ru/press/PR/?file=17072014_1430... 2014-07-17  \n",
       "3  http://www.cbr.ru/press/PR/?file=17072014_1615... 2014-07-17  \n",
       "4  http://www.cbr.ru/press/PR/?file=17072014_2043... 2014-07-17  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pr_old_extra = pd.DataFrame(good_articles)\n",
    "df_pr_old_extra.columns=[\"num\", \"datestr\", \"type\", \"header\", \"text\", \"url\"]\n",
    "df_pr_old_extra = df_pr_old_extra.drop(columns=['num'])\n",
    "df_pr_old_extra = df_pr_old_extra.reset_index(drop=True)\n",
    "\n",
    "# df_pr_old['date'] = [f\"{i[0]}-{months[i[1]]}-{i[2]}\" for i in df_new.datestr.str.split().tolist()]\n",
    "df_pr_old_extra['date'] = pd.to_datetime(df_pr_old_extra['datestr'], format='%d.%m.%Y')\n",
    "df_pr_old_extra.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объединяем часть 1 и 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat([df_pr_old, df_new, df_pr_old_extra]).drop_duplicates().sort_values(by=['date', 'type']).reset_index(drop=True)\n",
    "# df = df[['date','type','header','text', 'url']]\n",
    "# df = df[(df.date.dt.date <= datetime.date(2022, 2, 1)) & (df.date.dt.date <= datetime.date(2022, 2, 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df_pr_old_extra]).drop_duplicates().sort_values(by=['date', 'type']).reset_index(drop=True)\n",
    "df = df[['date','type','header','text', 'url']]\n",
    "df.to_csv(\"main_upd.csv\", encoding=\"utf-8\", sep=\";\", index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"main_upd.csv\", sep=\";\")\n",
    "df1 = pd.read_csv(\"data1.csv\")\n",
    "\n",
    "df.date = pd.to_datetime(df.date).dt.date\n",
    "\n",
    "df[\"rate_flag\"] = (df.header.isin(set(df1['information.text'])) | ((df.type==\"Пресс-релиз\") & \n",
    "                                                  (df.header.str.find(\"Банк России принял\") > -1) &\n",
    "                                                  (df.header.str.find(\"ключ\") > -1))) * 1\n",
    "df.to_csv(\"main_upd1.csv\", encoding=\"utf-8\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 3: добавляем данные и генерим текстовые переменные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"main_upd1.csv\", encoding=\"utf-8\", sep=\";\")\n",
    "df.date = pd.to_datetime(df.date).dt.date\n",
    "df = df[df.type != 'Новость']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_base = webdriver.Chrome(service=s)\n",
    "driver_base.maximize_window()\n",
    "res = dict()\n",
    "exc = []\n",
    "for i in tqdm(df[df.text.str.len() < 200].url.index):\n",
    "    try:\n",
    "        url = df.loc[i].url\n",
    "        driver_base.get(url)\n",
    "        res[i] = driver_base.find_elements(By.TAG_NAME, value='.landing-text')[0].text\n",
    "    except Exception:\n",
    "        exc.append(i)\n",
    "\n",
    "for i, t in res.items():\n",
    "    if len(t) < len(df.loc[i].text):\n",
    "        res.pop(i)\n",
    "\n",
    "for i, t in res.items():\n",
    "    df.loc[i, 'text'] = t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выступления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# даты выступлений совпадают с датами пресс-релизов\n",
    "df1 = df[df.type == 'Выступление']\n",
    "rate_dates = df1[df1.header.str.find(\"Заявление Председателя Банка России\") > -1].date\n",
    "print(len(set(rate_dates) - set(df[df.rate_flag == 1].date)))\n",
    "df.loc[df.date.isin(df[df.rate_flag == 1].date) & (df.type == 'Выступление'), \"rate_flag\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3754      https://www.cbr.ru/press/event/?id=5195\n",
       "3972      https://www.cbr.ru/press/event/?id=5196\n",
       "4085      https://www.cbr.ru/press/event/?id=5197\n",
       "4285      https://www.cbr.ru/press/event/?id=5198\n",
       "4425      https://www.cbr.ru/press/event/?id=5199\n",
       "                           ...                   \n",
       "13429    https://www.cbr.ru/press/event/?id=12361\n",
       "13478    https://www.cbr.ru/press/event/?id=12416\n",
       "13489    https://www.cbr.ru/press/event/?id=12429\n",
       "13504    https://www.cbr.ru/press/event/?id=12451\n",
       "13566    https://www.cbr.ru/press/event/?id=12542\n",
       "Name: url, Length: 132, dtype: object"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ показал, что выступления надо парсить иначе\n",
    "\n",
    "driver_base = webdriver.Chrome(service=s)\n",
    "driver_base.maximize_window()\n",
    "events = dict()\n",
    "exc = []\n",
    "for i in tqdm(df1.url.index):\n",
    "    try:\n",
    "        url = df1.loc[i].url\n",
    "        driver_base.get(url)\n",
    "        all_texts = driver_base.find_elements(By.TAG_NAME, value='.landing-text')\n",
    "        events[i] = all_texts[0].text\n",
    "    except Exception:\n",
    "        exc.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curlist = [i for i, t in events.items() if len(t) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [10:22<00:00,  4.72s/it]\n"
     ]
    }
   ],
   "source": [
    "# оказалось, что иногда надо брать вторый блок текста\n",
    "\n",
    "driver_base = webdriver.Chrome(service=s)\n",
    "driver_base.maximize_window()\n",
    "exc = []\n",
    "for i in tqdm(df1.url.index):\n",
    "    if i in curlist:\n",
    "        try:\n",
    "            url = df1.loc[i].url\n",
    "            driver_base.get(url)\n",
    "            all_texts = driver_base.find_elements(By.TAG_NAME, value='.landing-text')\n",
    "            events[i] = all_texts[1].text\n",
    "        except Exception:\n",
    "            exc.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, t in events.items():\n",
    "    if t is not None and ~df.loc[i].isna().any():\n",
    "        if len(t) < len(df.loc[i].text):\n",
    "            print(i, len(t), len(df.loc[i].text) - len(t))\n",
    "            events.pop(i)\n",
    "            \n",
    "for i, t in events.items():\n",
    "    df.loc[i, 'text'] = t \n",
    "    \n",
    "# df1 = df[(df.rate_flag == 1) & (df.type == 'Выступление')]\n",
    "# driver_base.get(df1.loc[11932].url)\n",
    "# all_texts = driver_base.find_elements(By.TAG_NAME, value='.landing-text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date         False\n",
       "type         False\n",
       "header       False\n",
       "text         False\n",
       "url          False\n",
       "rate_flag    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.header = df.header.str.replace(\"«\", '\"').str.replace(\"»\", '\"')\n",
    "df.text = df.text.str.replace(\"«\", '\"').str.replace(\"»\", '\"')\n",
    "df.text = df.text.str.replace(\"При использовании материала ссылка на Пресс-службу Банка России обязательна.\", '')\n",
    "df.text = df.text.str.strip()\n",
    "df.text = df.text.str.replace(\"\\n\", \" \")\n",
    "df.text = df.text.apply(lambda x: re.sub('[ ]+', ' ', x))\n",
    "\n",
    "df = df[df.text.str.len() > 130]\n",
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"main_upd2.csv\", encoding=\"utf-8\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выделим в выступлениях по ставке только слова председателя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(os.path.dirname(os.getcwd()) + \"/data/main_upd2.csv\"), encoding=\"utf-8\", sep=\";\")\n",
    "df.text = df.text.str.replace(\"«\", '\"').str.replace(\"»\", '\"')\n",
    "events_id = df[(df.rate_flag == 1) & (df.type == \"Выступление\")].index\n",
    "raw_answers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = df.loc[events_id].iloc[0].text\n",
    "t = re.sub(\"ВОПРОС\", \"ВОПРОС&123\", t)\n",
    "t = re.split(\" Э.С. НАБИУЛЛИНА | С.А. ШВЕЦОВ | К.В. ЮДАЕВА \", t)\n",
    "t = [i[:i.find(\"ВОПРОС&123\")].strip().replace(\"Э.С. НАБИУЛЛИНА \", \"\")\n",
    "     if i.find(\"ВОПРОС&123\") > -1 else i for i in t]\n",
    "raw_answers = {events_id[0]: t}\n",
    "t = \" \".join(t)\n",
    "df.loc[events_id[0], \"text\"] = t\n",
    "events_id = events_id[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_parser2(t, ind):\n",
    "    l = t.find(\"Сессия вопросов и ответов\")\n",
    "    restext = [t[:l].strip()]\n",
    "    t = t[l + len(\"Сессия вопросов и ответов для СМИ\"):].strip()\n",
    "    t = re.sub(\"Э.С. НАБИУЛЛИНА:\", \"Э.С. НАБИУЛЛИНА\", t)\n",
    "    t = re.split(\"Э.С. НАБИУЛЛИНА\", t)\n",
    "    for i in t:\n",
    "        if len(i) > 0:\n",
    "            i = re.sub(\"ВОПРОС:\", \"ВОПРОС\", i)\n",
    "            i = re.sub(\"Вопрос:\", \"ВОПРОС\", i)\n",
    "            i = re.sub(\"Вопрос\", \"ВОПРОС\", i)\n",
    "            i = re.sub(\"Вопрос \\((.)+\\):\", \"ВОПРОС \\((.)+\\)\", i)\n",
    "            i = re.sub(\"Вопрос \\((.)+\\)\", \"ВОПРОС\", i)\n",
    "            i = re.sub(\"ВОПРОС \\((.)+\\):\", \"ВОПРОС \\((.)+\\)\", i)\n",
    "            m = re.search(\"ВОПРОС \\((.)+\\)|ВОПРОС\", i)\n",
    "            if m:\n",
    "                found = m.group(0)\n",
    "                restext.append(i[:i.find(found)].strip())\n",
    "            else:\n",
    "                restext.append(i.strip())\n",
    "    raw_answers[ind] = restext\n",
    "    restext = \" \".join(restext)\n",
    "    return restext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[events_id, \"text\"] = df.loc[events_id, \"text\"].str.replace(\"Сессия вопросов и ответов для СМИ\", \n",
    "                                                                  \"Сессия вопросов и ответов\")\n",
    "\n",
    "df.loc[events_id, \"text\"] = df.loc[events_id, \"text\"].str.replace(\"Сессия вопросов и ответов СМИ\", \n",
    "                                                                  \"Сессия вопросов и ответов\")\n",
    "\n",
    "group1 = df.loc[events_id, \"text\"].str.find(\"Сессия вопросов и ответов\") > -1\n",
    "group2 = group1[(~group1).tolist()]\n",
    "\n",
    "for i in events_id[(group1).tolist()]:\n",
    "    df.loc[i, \"text\"] = text_parser2(df.loc[i, \"text\"], i)    \n",
    "    if df.loc[i, \"text\"].find(\"Наби\") > -1 or \\\n",
    "        df.loc[i, \"text\"].find(\"ВОПРОС\") > -1 or\\\n",
    "        df.loc[i, \"text\"].find(\"НАБИ\") > -1 or\\\n",
    "        df.loc[i, \"text\"].find(\"Вопрос\") > -1:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['splittext'] = None\n",
    "for i, t in raw_answers.items():\n",
    "    df.loc[i, \"splittext\"] = \"&&&&\".join(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([9656], dtype='int64')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# здесь не было сессии ответов\n",
    "events_id[(~group1).tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"main_upd4.csv\", encoding=\"utf-8\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чистим от мусора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_directory = os.path.dirname(os.getcwd()) \n",
    "# data_folder = os.path.normpath(os.path.join(current_directory + \"/data\"))\n",
    "# symbols = [\",\", \".\", \"'\", \"!\", '\"', \"#\", \"$\", \"%\", \"&\", \"(\", \")\", \"*\", \"+\", \"-\", \".\", \"/\", \":\", \";\", \"<\", \"=\", '>', \"?\",\n",
    "#       \"@\", \"[\", \"\\\\\", \"]\", \"^\", \"_\", '`', \"{\", \"|\", \"}\", '~', '\\t', '\\n']\n",
    "# # df = pd.read_csv(os.path.join(data_folder + \"/main_upd3.csv\"), encoding=\"utf-8\", sep=\";\")\n",
    "# # for t in df.text:\n",
    "# t = df.iloc[0].text\n",
    "# t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
